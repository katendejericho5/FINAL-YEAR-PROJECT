{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"R_x6UZ7lSNr8","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1715518015470,"user_tz":-180,"elapsed":8543,"user":{"displayName":"Final Year Project","userId":"08500182293149651870"}},"outputId":"3dff2393-21ee-47bd-e8f3-a15dd8f643e6"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting tf_keras_vis\n","  Downloading tf_keras_vis-0.8.7-py3-none-any.whl (52 kB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/52.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.5/52.5 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from tf_keras_vis) (1.11.4)\n","Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from tf_keras_vis) (9.4.0)\n","Collecting deprecated (from tf_keras_vis)\n","  Downloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n","Requirement already satisfied: imageio in /usr/local/lib/python3.10/dist-packages (from tf_keras_vis) (2.31.6)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tf_keras_vis) (24.0)\n","Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.10/dist-packages (from deprecated->tf_keras_vis) (1.14.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from imageio->tf_keras_vis) (1.25.2)\n","Installing collected packages: deprecated, tf_keras_vis\n","Successfully installed deprecated-1.2.14 tf_keras_vis-0.8.7\n"]}],"source":["!pip install tf_keras_vis"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EuBkb6w5Mx4B","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1715518016946,"user_tz":-180,"elapsed":1488,"user":{"displayName":"Final Year Project","userId":"08500182293149651870"}},"outputId":"9ed38f7a-db88-41c8-afb6-6fd7bfef7f07"},"outputs":[{"output_type":"stream","name":"stdout","text":["Tensorflow recognized 1 GPUs\n"]}],"source":["# %reload_ext autoreload\n","# %autoreload 2\n","\n","import numpy as np\n","from matplotlib import pyplot as plt\n","%matplotlib inline\n","\n","import tensorflow as tf\n","from tf_keras_vis.utils import num_of_gpus\n","\n","_, gpus = num_of_gpus()\n","print('Tensorflow recognized {} GPUs'.format(gpus))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZIUJ14TDWOC7","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1715518060064,"user_tz":-180,"elapsed":43124,"user":{"displayName":"Final Year Project","userId":"08500182293149651870"}},"outputId":"727c4bfe-e047-474e-ec7c-b1df4f9e9309"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ye4RCXCKWo6F"},"outputs":[],"source":["import os\n","import cv2\n","import numpy as np\n","import pandas as pd\n","from glob import glob\n","import matplotlib.pyplot as plt\n","from tensorflow.keras.models import Model, Sequential\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.layers import Dense, LSTM, Bidirectional, TimeDistributed, Flatten, Dropout\n","from tensorflow.keras.optimizers import Adam\n","from sklearn.model_selection import train_test_split\n","from tensorflow.keras.callbacks import ModelCheckpoint\n","from tensorflow.keras.layers import Input, Lambda, Dense, Flatten\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.applications.vgg19 import VGG19\n","from tensorflow.keras.preprocessing import image"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"V8oqsBRXXJyV","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1715518073040,"user_tz":-180,"elapsed":11619,"user":{"displayName":"Final Year Project","userId":"08500182293149651870"}},"outputId":"1b5e44de-9b35-48bc-92c1-828720172f9b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Total Length of Training Images: 2700\n"]}],"source":["import os\n","train_dir = '/content/drive/MyDrive/Kaggle3/Test_Alphabet'\n","categories = os.listdir(train_dir)\n","len(categories)\n","# length of training images\n","length = 0\n","train_images_names_and_paths = {}\n","\n","for cat in categories:\n","    train_images_names_and_paths[cat] = os.listdir(train_dir + '/' + cat)\n","    length += len(os.listdir(train_dir + '/' + cat))\n","\n","print('Total Length of Training Images:', length)"]},{"cell_type":"code","source":["os.listdir(train_dir)"],"metadata":{"id":"bKILblTXlPvj","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1715518073041,"user_tz":-180,"elapsed":30,"user":{"displayName":"Final Year Project","userId":"08500182293149651870"}},"outputId":"26b10484-7c40-46e7-94e6-08147867f4a8"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['A',\n"," 'B',\n"," 'Blank',\n"," 'C',\n"," 'D',\n"," 'E',\n"," 'F',\n"," 'G',\n"," 'H',\n"," 'I',\n"," 'J',\n"," 'K',\n"," 'L',\n"," 'M',\n"," 'N',\n"," 'O',\n"," 'P',\n"," 'Q',\n"," 'R',\n"," 'S',\n"," 'T',\n"," 'U',\n"," 'V',\n"," 'W',\n"," 'X',\n"," 'Y',\n"," 'Z']"]},"metadata":{},"execution_count":6}]},{"cell_type":"code","source":["import numpy as np\n","import matplotlib.pyplot as plt\n","from keras.datasets import mnist\n","from keras.models import Sequential\n","from keras.layers import Dense, Flatten\n","from keras.applications import VGG19\n","from keras.utils import to_categorical\n","from sklearn.metrics import confusion_matrix\n","import seaborn as sns\n","from keras.preprocessing.image import img_to_array, array_to_img\n","from keras.applications.vgg19 import preprocess_input\n"],"metadata":{"id":"S3Xy9R4Ylzhx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from keras.preprocessing.image import ImageDataGenerator\n","\n","train_data_dir = '/content/drive/MyDrive/Kaggle3/Train_Alphabet/'\n","test_data_dir = '/content/drive/MyDrive/Kaggle3/Test_Alphabet/'\n","\n","# Initialize ImageDataGenerator for train and test data\n","train_datagen = ImageDataGenerator(rescale=1./255)\n","test_datagen = ImageDataGenerator(rescale=1./255)\n","\n","# Flow training images in batches of 32 using train_datagen generator\n","train_generator = train_datagen.flow_from_directory(\n","        train_data_dir,\n","        target_size=(48, 48),\n","        batch_size=32,\n","        class_mode='categorical')\n","\n","# Flow validation images in batches of 32 using test_datagen generator\n","test_generator = test_datagen.flow_from_directory(\n","        test_data_dir,\n","        target_size=(48, 48),\n","        batch_size=32,\n","        class_mode='categorical')\n","\n","# Now you can use train_generator and test_generator for training and testing your model\n"],"metadata":{"id":"mZjzeWU7mKWR","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1715518084539,"user_tz":-180,"elapsed":11520,"user":{"displayName":"Final Year Project","userId":"08500182293149651870"}},"outputId":"dac4d500-a680-482f-ecb9-c544d2499155"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 24301 images belonging to 27 classes.\n","Found 2700 images belonging to 27 classes.\n"]}]},{"cell_type":"code","source":["\n","from tensorflow.keras.applications import VGG19\n","from tensorflow.keras.layers import Flatten, Dense\n","from tensorflow.keras.models import Model\n","\n","# Load the VGG19 model without the top layer\n","base_model = VGG19(weights='imagenet', include_top=False, input_shape=(48, 48, 3))\n","\n","# Freeze the base model layers\n","base_model.trainable = False\n","\n","# Add our own classification layers on top\n","x = Flatten()(base_model.output)\n","x = Dense(128, activation='relu')(x)\n","predictions = Dense(27, activation='softmax')(x)\n","\n","# Create the final model\n","model = Model(inputs=base_model.input, outputs=predictions)\n","\n","# Compile the model\n","model.compile(optimizer='adam',\n","              loss='categorical_crossentropy',\n","              metrics=['accuracy'])\n","\n","# Train the model\n","history = model.fit(\n","      train_generator,\n","      steps_per_epoch=train_generator.samples // train_generator.batch_size,\n","      epochs=12,\n","      validation_data=test_generator,\n","      validation_steps=test_generator.samples // test_generator.batch_size)"],"metadata":{"id":"rh3ROtFhmcid"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["exp_model_path = '/content/drive/MyDrive/my_model.h5'\n","\n","# Save the model\n","model.save(exp_model_path)"],"metadata":{"id":"CqOlI2tP8Q_K"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from tensorflow.keras.models import load_model\n","\n","# Load the model\n","model = load_model('/content/drive/MyDrive/my_model.h5')\n"],"metadata":{"id":"uKWbn3TsPtLG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model_path = '/content/drive/MyDrive/exp_model.keras'\n","\n","model.save(model_path)"],"metadata":{"id":"f2hL6rPtGOVt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model"],"metadata":{"id":"Mm5hOcgcxX2M"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.summary"],"metadata":{"id":"oZeKIQ95yG26"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AqHlRbB25nVw"},"outputs":[],"source":["import os\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from PIL import Image\n","from tensorflow.keras.applications.vgg19 import preprocess_input\n","from tensorflow.keras.preprocessing.image import load_img\n","\n","# Folder containing the images\n","test_data_dir = '/content/drive/MyDrive/Kaggle3/Test_Alphabet/'\n","\n","# Get the list of subdirectories (folders) inside test_data_dir\n","subdirectories = [subdir for subdir in os.listdir(test_data_dir) if os.path.isdir(os.path.join(test_data_dir, subdir))]\n","\n","# Load one image from each subdirectory\n","images = []\n","image_titles = []\n","for subdir in subdirectories:\n","    subdir_path = os.path.join(test_data_dir, subdir)\n","    image_filenames = [filename for filename in os.listdir(subdir_path) if filename.endswith(('.png', '.jpg', '.jpeg'))]\n","    if image_filenames:\n","        # Pick the first image in the directory\n","        filename = image_filenames[0]\n","        img = load_img(os.path.join(subdir_path, filename), target_size=(48, 48))\n","        images.append(np.array(img))\n","        image_titles.append(subdir)\n","\n","# Plotting\n","num_images = len(images)\n","fig, ax = plt.subplots(num_images, 1, figsize=(6, 6*num_images))\n","\n","for i, (img, title) in enumerate(zip(images, image_titles)):\n","    ax[i].imshow(img)\n","    ax[i].set_title(title, fontsize=12)\n","    ax[i].axis('off')\n","\n","plt.tight_layout()\n","plt.show()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"81w9q2ZY9Dtb"},"outputs":[],"source":["from tf_keras_vis.utils.model_modifiers import ReplaceToLinear\n","\n","replace2linear = ReplaceToLinear()"]},{"cell_type":"code","source":["images[0].shape"],"metadata":{"id":"S9nW8IR5dhRu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from tf_keras_vis.utils.scores import CategoricalScore\n","\n","# Create an empty list to store the scores for each image\n","scores = []\n","\n","for img in images:\n","    # Reshape the image to match the model's input shape if needed\n","    # img = np.expand_dims(img, axis=0)  # Uncomment if needed\n","\n","    # Compute the prediction probabilities for the image using the model\n","    pred_probs = model.predict(img.reshape(1, 48, 48, 3))  # Assuming the input shape is (48, 48, 3)\n","\n","    # Extract the index of the class with the highest probability\n","    pred_class_index = np.argmax(pred_probs)\n","\n","    # Append the index to the scores list\n","    scores.append(pred_class_index)\n","\n","# Convert the list of scores to a CategoricalScore object\n","score = CategoricalScore(scores)\n"],"metadata":{"id":"zxjULmtaagce"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from matplotlib import pyplot as plt\n","from tf_keras_vis.gradcam import Gradcam\n","from tf_keras_vis.utils.model_modifiers import ReplaceToLinear\n","from tf_keras_vis.utils.scores import CategoricalScore\n","import numpy as np\n","\n","# Create Gradcam object\n","replace2linear = ReplaceToLinear()\n","gradcam = Gradcam(model, model_modifier=replace2linear, clone=True)\n","\n","# Create an empty list to store the heatmaps\n","heatmaps = []\n","\n","# Iterate over each image\n","for img in images:\n","    # Compute the prediction probabilities for the image using the model\n","    pred_probs = model.predict(np.expand_dims(img, axis=0))\n","    # Extract the index of the class with the highest probability\n","    pred_class_index = np.argmax(pred_probs)\n","    # Create a score object with the predicted class index\n","    score = CategoricalScore([pred_class_index])\n","    # Generate heatmap with GradCAM for the current image\n","    cam = gradcam(score, img, penultimate_layer=-1)\n","    # Append the heatmap to the heatmaps list\n","    heatmaps.append(cam)\n","\n","# Render images with heatmaps\n","fig, axes = plt.subplots(1, len(images), figsize=(15, 5))\n","for i, (img, cam) in enumerate(zip(images, heatmaps)):\n","    heatmap = np.uint8(cm.jet(cam)[..., :3] * 25)\n","    axes[i].imshow(img)\n","    axes[i].imshow(heatmap, cmap='jet', alpha=0.5) # overlay\n","    axes[i].axis('off')\n","plt.show()\n"],"metadata":{"id":"mkYrTHpTVzOA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","\n","# Create an empty list to store the predicted class indices for each image\n","predicted_classes = []\n","\n","# Iterate over each image\n","for img in images:\n","    # Reshape the image to match the model's input shape if needed\n","    # img = np.expand_dims(img, axis=0)  # Uncomment if needed\n","\n","    # Compute the prediction probabilities for the image using the model\n","    pred_probs = model.predict(img.reshape(1, 48, 48, 3))  # Assuming the input shape is (48, 48, 3)\n","\n","    # Extract the index of the class with the highest probability\n","    pred_class_index = np.argmax(pred_probs)\n","\n","    # Append the predicted class index to the list\n","    predicted_classes.append(pred_class_index)\n","\n","# Print the predicted class indices\n","print(\"Predicted class indices:\")\n","print(predicted_classes)\n","\n","# Print the corresponding class labels\n","class_labels = [image_titles[i] for i in predicted_classes]\n","print(\"\\nCorresponding class labels:\")\n","print(class_labels)\n"],"metadata":{"id":"9vx0CHynwOaa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(image_titles)"],"metadata":{"id":"ePToeNxPxCsX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install vis"],"metadata":{"id":"JZQilrW481Mt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import keras\n","import vis"],"metadata":{"id":"cEfoqy_v8RAd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from keras.preprocessing.image import load_img, img_to_array\n","_img = load_img('/content/drive/MyDrive/Kaggle3/Test_Alphabet/A/test.png', target_size=(48,48))\n","plt.imshow(_img)\n","plt.show()"],"metadata":{"id":"q1qrF8_N-R7B"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["img = img_to_array(_img)\n","img = preprocess_input(img)\n","y_pred = model.predict(img[np.newaxis,...])\n","class_idx_sorted = np.argsort(y_pred.flatten())[::-1]"],"metadata":{"id":"42hkiP_5_jmw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import tensorflow as tf"],"metadata":{"id":"Xm_gf-ysO6-s"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from tf_keras_vis.utils.model_modifiers import ReplaceToLinear\n","\n","replace2linear = ReplaceToLinear()\n","gradcam = Gradcam(model, model_modifier=replace2linear, clone=True)\n","\n","# Create an empty list to store the heatmaps\n","heatmaps = []\n","\n","# Iterate over each image\n","for img in images:\n","    # Preprocess the image\n","    img = tf.cast(img, tf.float32) / 255.0\n","\n","    # Compute the prediction probabilities for the image using the model\n","    pred_probs = model.predict(np.expand_dims(img, axis=0))\n","    # Extract the index of the class with the highest probability\n","    pred_class_index = np.argmax(pred_probs)\n","    # Create a score object with the predicted class index\n","    score = CategoricalScore([pred_class_index])\n","    # Generate heatmap with GradCAM for the current image\n","    try:\n","        cam = gradcam(score, img, penultimate_layer=-1)\n","    except Exception as e:\n","        print(f\"Error generating heatmap for image: {e}\")\n","        continue\n","    # Append the heatmap to the heatmaps list\n","    heatmaps.append(cam)\n"],"metadata":{"id":"ieJyVgeTOZpb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","import matplotlib.cm as cm\n","\n","# Render images with heatmaps\n","fig, axes = plt.subplots(1, len(images), figsize=(15, 5))\n","for i, (img, cam) in enumerate(zip(images, heatmaps)):\n","    heatmap = np.uint8(cm.jet(cam)[..., :3] * 25)\n","    heatmap = heatmap.squeeze()  # Remove the first dimension\n","    axes[i].imshow(img)\n","    axes[i].imshow(heatmap, cmap='jet', alpha=0.5)  # overlay\n","    axes[i].axis('off')\n","plt.show()"],"metadata":{"id":"3fzLTHJ0P_fD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Render images with heatmaps\n","fig, axes = plt.subplots(1, len(images), figsize=(15, 5))\n","for i, (img, cam) in enumerate(zip(images, heatmaps)):\n","    # Convert the image to BGR format for OpenCV\n","    img_bgr = cv2.cvtColor(np.uint8(img), cv2.COLOR_RGB2BGR)\n","\n","    # Generate the heatmap for the current image\n","    heatmap = np.uint8(cm.jet(cam)[..., :3] * 25)\n","    heatmap = heatmap.squeeze()  # Remove the first dimension\n","\n","    # Overlay the heatmap on the original image\n","    overlay_img = cv2.addWeighted(img_bgr, 0.7, cv2.applyColorMap(heatmap, cv2.COLORMAP_JET), 0.3, 0)\n","\n","    # Display the image with the heatmap\n","    axes[i].imshow(cv2.cvtColor(overlay_img, cv2.COLOR_BGR2RGB))  # Convert BGR to RGB for displaying with matplotlib\n","    axes[i].axis('off')\n","\n","plt.show()"],"metadata":{"id":"scoTjQsjTCZw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.summary()"],"metadata":{"id":"zclSXdDxZJET"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import tensorflow as tf\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from tensorflow.keras.preprocessing.image import img_to_array\n","from tensorflow.keras.applications.vgg19 import preprocess_input\n","\n","def get_heatmap(model, block5_conv4, image):\n","    # Expand dimensions to create a batch of 1 image\n","    image = np.expand_dims(image, axis=0)\n","\n","    # Preprocess the image\n","    processed_image = preprocess_input(image)\n","\n","    # Define the gradient model\n","    grad_model = tf.keras.models.Model([model.inputs], [model.get_layer(block5_conv4).output, model.output])\n","\n","    with tf.GradientTape() as tape:\n","        last_conv_layer_output, preds = grad_model(processed_image)\n","        class_idx = tf.argmax(preds[0])\n","        class_output = preds[:, class_idx]\n","        grads = tape.gradient(class_output, last_conv_layer_output)\n","\n","    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n","    heatmap = tf.reduce_mean(tf.multiply(pooled_grads, last_conv_layer_output), axis=-1)\n","    heatmap = np.maximum(heatmap, 0)\n","    heatmap /= np.max(heatmap)\n","\n","    return heatmap\n","\n","def overlay_heatmap(heatmap, image):\n","    heatmap = np.uint8(255 * heatmap)\n","    heatmap = tf.keras.preprocessing.image.array_to_img(heatmap)\n","    heatmap = heatmap.resize((image.shape[1], image.shape[0]))\n","    heatmap = tf.keras.preprocessing.image.img_to_array(heatmap)\n","\n","    overlayed_img = heatmap * 0.4 + image\n","\n","    return overlayed_img / np.max(overlayed_img)\n","\n","\n","\n","# Name of the last convolutional layer\n","last_conv_layer_name = 'block5_conv4'  # Change this according to your model architecture\n","\n","# Load and preprocess the images\n","test_data_dir = '/content/drive/MyDrive/Kaggle3/Test_Alphabet/'\n","subdirectories = [subdir for subdir in os.listdir(test_data_dir) if os.path.isdir(os.path.join(test_data_dir, subdir))]\n","\n","for subdir in subdirectories:\n","    subdir_path = os.path.join(test_data_dir, subdir)\n","    image_filenames = [filename for filename in os.listdir(subdir_path) if filename.endswith(('.png', '.jpg', '.jpeg'))]\n","    if image_filenames:\n","        # Load the image\n","        filename = image_filenames[0]\n","        img = load_img(os.path.join(subdir_path, filename), target_size=(48, 48))\n","        img_array = img_to_array(img)\n","\n","        # Get the heatmap\n","        heatmap = get_heatmap(model, last_conv_layer_name, img_array)\n","\n","        # Overlay heatmap on the image\n","        overlayed_img = overlay_heatmap(heatmap, img_array)\n","\n","        # Plot the original image, heatmap, and overlayed image\n","        plt.figure(figsize=(12, 6))\n","        plt.subplot(1, 3, 1)\n","        plt.imshow(img)\n","        plt.title('Original Image')\n","        plt.axis('off')\n","\n","        plt.subplot(1, 3, 2)\n","        plt.imshow(heatmap)\n","        plt.title('Heatmap')\n","        plt.axis('off')\n","\n","        plt.subplot(1, 3, 3)\n","        plt.imshow(overlayed_img)\n","        plt.title('Overlayed Image')\n","        plt.axis('off')\n","\n","        plt.show()\n"],"metadata":{"id":"igPpbVuWYSa1"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[],"gpuType":"L4"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}